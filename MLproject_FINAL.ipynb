{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import svm\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "import graphviz \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting working directory\n",
    "%cd \"~/Box Sync/ML Education Project\"\n",
    "\n",
    "#bringing in master file for 20140-15\n",
    "df14 = pd.read_csv('MERGED2014_15_PP.csv',error_bad_lines=False)\n",
    "df10 = pd.read_csv('MERGED2010_11_PP.csv',error_bad_lines=False)\n",
    "#df.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bringing in file with variable that I selected\n",
    "#using Dymtro's variable selection file col_column\n",
    "col=pd.read_csv('VariableSelectionMLV2.csv')\n",
    "col.head()\n",
    "\n",
    "#converting dataframe to list \n",
    "col_names = col.Variable.tolist()\n",
    "\n",
    "SATdf14 = df14[['SATVR25','SATVR75']].copy()\n",
    "SATdf10 = df10[['SATVR25','SATVR75']].copy()\n",
    "#subsetting dataset by col_names\n",
    "df14=df14.loc[:, col_names]\n",
    "df10=df10.loc[:, col_names]\n",
    "\n",
    "\n",
    "#df14.head()\n",
    "df10.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lb_make = LabelEncoder()\n",
    "#df = df.dropna(how='any',axis=0) \n",
    "#df = df[pd.notnull(df['RET_FT4'])]\n",
    "#df = df[np.isfinite(df['RET_FT4'])]\n",
    "#print(df)\n",
    "df14 = df14.replace('PrivacySuppressed', '', regex=True)\n",
    "df10 = df10.replace('PrivacySuppressed', '', regex=True)\n",
    "for n in range(3,64):\n",
    "    df14[df14.columns[n]]=pd.to_numeric(df14[df14.columns[n]], errors='coerce')\n",
    "    df10[df10.columns[n]]=pd.to_numeric(df10[df10.columns[n]], errors='coerce')\n",
    "\n",
    "meanTarget14=df14[\"RET_FT4\"].mean()\n",
    "meanTarget10=df10[\"RET_FT4\"].mean()\n",
    "\n",
    "#print(meanTarget)\n",
    "df14=df14.fillna(df14.mean())\n",
    "df10=df10.fillna(df10.mean())\n",
    "df14['SATVR25']=SATdf14['SATVR25']\n",
    "df14['SATVR75']=SATdf14['SATVR75']\n",
    "df10['SATVR25']=SATdf10['SATVR25']\n",
    "df10['SATVR75']=SATdf10['SATVR75']\n",
    "\n",
    "df10 = df10[df10.RET_FT4 !=meanTarget10 ]\n",
    "df14 = df14[df14.RET_FT4 !=meanTarget14 ]\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#ohe = OneHotEncoder()\n",
    "#x= df14['CONTROL']\n",
    "#x[x==1]='PUBLIC'\n",
    "#x[x==2]='PRIVATE'\n",
    "#x[x==3]='PROFIT'\n",
    "#df14['CONTROL']=x\n",
    "#control = df14['CONTROL']\n",
    "\n",
    "\n",
    "#control = lb_make.fit_transform(control)\n",
    "\n",
    "#control_enc = ohe.fit_transform(control.reshape(-1,1)).toarray()\n",
    "\n",
    "#control_enc = pd.DataFrame(control_enc, columns=lb_make.classes_)\n",
    "#df=pd.concat([df,control_enc],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#df.to_csv(\"o5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10.to_csv(\"Education10.csv\")\n",
    "df14.to_csv(\"Education14.csv\")\n",
    "print(df10.shape)\n",
    "print(df14.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After imputing SAT's from R miss algo\n",
    "df14 = pd.read_csv('ImputedEducation14.csv',error_bad_lines=False)\n",
    "df10 = pd.read_csv('ImputedEducation10.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding suffix to column year 14\n",
    "df14_suf = df14.add_suffix('_Post')\n",
    "df14_suf.head()\n",
    "df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just dropping some extra columns that are being created \n",
    "\n",
    "df14_suf=df14_suf.drop(df14_suf.columns[0],axis=1)\n",
    "df14_suf=df14_suf.drop('X_Post',axis=1)\n",
    "display(df14_suf)\n",
    "df10=df10.drop(df10.columns[0],axis=1)\n",
    "df10=df10.drop('X',axis=1)\n",
    "#df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(df10, df14_suf.rename(columns={'UNITID_Post':'UNITID'}), on='UNITID',  how='left')\n",
    "\n",
    "\n",
    "\n",
    "merge.head()\n",
    "display(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#saving column names\n",
    "list_10=df10.columns.tolist()\n",
    "#UniList=list_10[0]\n",
    "del list_10[0]\n",
    "print(list_10)\n",
    "\n",
    "\n",
    "for i in list_10:\n",
    "    string = str(i)\n",
    "    post = '_Post'\n",
    "    i_post = string + post\n",
    "    x = string+'_d'\n",
    "    print(x)\n",
    "    d = merge[i_post] - merge[i]\n",
    "    merge[x]=d\n",
    "\n",
    "    \n",
    "#merge.head()\n",
    "\n",
    "#merge['UNITID_d']=UniList\n",
    "#print(UniList)\n",
    "display(merge)\n",
    "#merge.to_csv(\"MyEducationTest.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#then drop all variables that are not _d, and keep UNITID\n",
    "merge = merge.drop(merge.columns.to_series()[\"SATVR25\":\"UGDS_UNKN_Post\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the file which we need to work on(MyEducationTest.csv)\n",
    "merge.head()\n",
    "df = merge\n",
    "merge=merge.dropna(how='any')\n",
    "print(merge.shape)\n",
    "\n",
    "merge.to_csv(\"MyEducationTest.csv\")\n",
    "display(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The loop finding difference between two years\n",
    "\n",
    "\n",
    "#print(SATdf)\n",
    "#df['SATVR25']=SATdf['SATVR25']\n",
    "#df['SATVR75']=SATdf['SATVR75']\n",
    "#print(df)\n",
    "#Num_cols = df14['UNITID'].count()\n",
    "#print(Num_cols)\n",
    "#for c in range(0,Num_cols-1):\n",
    " #   if (df14.iloc[[c]].UNITID==df10.iloc[[c]].UNITID):\n",
    "  #   df14.set_index('UNITID').subtract(df10.set_index('UNITID'), fill_value=0)   \n",
    "   # df.iloc[[2]]\n",
    "\n",
    "#df14.to_csv(\"ML.csv\")\n",
    "#bigdata = pd.concat([df, SATdf], ignore_index=True)\n",
    "#print(bigdata)\n",
    "#bigdata.to_csv(\"new.csv\")\n",
    "\n",
    "\n",
    "\n",
    "#df['diff'] = df['market price'] - df['apple price']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore this cell\n",
    "\n",
    "#df.columns.get_loc(\"SATVR25\")\n",
    "#col_list=['SATVR25']\n",
    "#df=df.dropna(subset=col_list)\n",
    "#print(df)\n",
    "#df.to_csv(\"Education.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to create the difference dataframes \n",
    "\n",
    "import scipy\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import os.path\n",
    "import csv\n",
    "\n",
    "df2014_15 = pd.read_csv('MERGED2014_15_PP.csv', low_memory=False)\n",
    "\n",
    "col2014_15=pd.read_csv('VariableSelectionV3.csv')\n",
    "\n",
    "\n",
    "#converting dataframe to list \n",
    "col_names2014_15 = col2014_15.Variable.tolist()\n",
    "\n",
    "#subsetting dataset by col_names\n",
    "df2014_15=df2014_15.loc[:, col_names2014_15]\n",
    "\n",
    "\n",
    "alpha = 0.37 # will delite columns which has more than alpha percent of missing data\n",
    "\n",
    "print(\"Shape of initial df is\",df2014_15.shape)\n",
    "#df = df[ abs(df.RET_FT4 - meanTarget) > 0.00001]\n",
    "df2014_15 = df2014_15[df2014_15[\"RET_FT4\"].notnull()] \n",
    "print(\"Shape of df after droping without retention rate is\",df2014_15.shape)\n",
    "print(df2014_15.head())\n",
    "\n",
    "print(\"Deal with PrivacySuppressed\")\n",
    "d2014_15 = {'PrivacySuppressed': np.NaN}\n",
    "df2014_15 = df2014_15.replace(d2014_15)\n",
    "\n",
    "print(\"Droping columns\")\n",
    "len_df2014_15 = df2014_15.shape[0]\n",
    "df12014_15 = df2014_15.isna().sum()\n",
    "n=0\n",
    "\n",
    "for index in df12014_15:\n",
    "\tif df12014_15[df12014_15.index[n]] > alpha*len_df2014_15:\n",
    "\t\tdf2014_15 = df2014_15.drop(df12014_15.index[n], axis=1)\n",
    "\t\tcol_names2014_15.remove(df12014_15.index[n])\n",
    "\tn = n + 1\n",
    "print(\"Shape of df after droping columns which has more than alpha percent of missing data\",df2014_15.shape)\n",
    "\n",
    "\n",
    "\n",
    "df2014_15.to_csv('2014_2015.csv', encoding='utf-8', columns=col_names2014_15)\n",
    "\n",
    "\n",
    "\n",
    "print(\"The same for 2010-11\")\n",
    "\n",
    "df2010_11 = pd.read_csv('MERGED2010_11_PP.csv', low_memory=False)\n",
    "\n",
    "print(df2010_11.head())\n",
    "\n",
    "col2010_11=pd.read_csv('VariableSelectionV3.csv')\n",
    "print(col2010_11.head())\n",
    "\n",
    "#converting dataframe to list \n",
    "col_names2010_11 = col2010_11.Variable.tolist()\n",
    "\n",
    "#subsetting dataset by col_names\n",
    "df2010_11=df2010_11.loc[:, col_names2010_11]\n",
    "print(df2010_11.head())\n",
    "\n",
    "print(df2010_11.shape)\n",
    "\n",
    "df2010_11 = df2010_11[df2010_11[\"RET_FT4\"].notnull()] \n",
    "print(df2010_11.shape)\n",
    "\n",
    "print(\"Deal with PrivacySuppressed\")\n",
    "d2010_11 = {'PrivacySuppressed': np.NaN}\n",
    "df2010_11 = df2010_11.replace(d2010_11)\n",
    "\n",
    "print(\"Droping columns\")\n",
    "len_df2010_11 = df2010_11.shape[0]\n",
    "df12010_11 = df2010_11.isna().sum()\n",
    "n=0\n",
    "\n",
    "for index in df12010_11:\n",
    "\tif df12010_11[df12010_11.index[n]] > alpha*len_df2010_11:\n",
    "\t\tdf2010_11 = df2010_11.drop(df12010_11.index[n], axis=1)\n",
    "\t\tcol_names2010_11.remove(df12010_11.index[n])\n",
    "\tn = n + 1\n",
    "print(df2010_11.shape)\n",
    "\n",
    "\n",
    "\n",
    "df2014_15.to_csv('2010_2011.csv', encoding='utf-8', columns=col_names2010_11)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "col_common = list(set(col_names2014_15).intersection(col_names2010_11))\n",
    "print(len(col_common))\n",
    "print(col_common)\n",
    "\n",
    "df = pd.DataFrame(col_common)\n",
    "df.to_csv('col_common.csv', index=False )\n",
    "\n",
    "df2014_15colcommon = df2014_15[col_common]\n",
    "df2010_11colcommon = df2010_11[col_common]\n",
    "print(df2014_15colcommon.shape)\n",
    "print(df2010_11colcommon.shape)\n",
    "\n",
    "print(df2010_11colcommon.head())\n",
    "\n",
    "df2014_15colcommon.to_csv('2014_2015_colcommon.csv', encoding='utf-8', columns=col_common)\n",
    "df2010_11colcommon.to_csv('2010_2011_colcommon.csv', encoding='utf-8', columns=col_common)\n",
    "\n",
    "print(df2014_15colcommon.shape)\n",
    "commonUNITID = np.intersect1d(df2014_15colcommon[\"UNITID\"], df2010_11colcommon[\"UNITID\"])\n",
    "print (commonUNITID[0])\n",
    "print(len(commonUNITID))\n",
    "\n",
    "dfcommonuniv2014 = df2014_15colcommon[df2014_15colcommon[\"UNITID\"].isin(commonUNITID)]\n",
    "print(dfcommonuniv2014.shape)\n",
    "\n",
    "dfcommonuniv2010 = df2010_11colcommon[df2010_11colcommon[\"UNITID\"].isin(commonUNITID)]\n",
    "print(dfcommonuniv2010.shape)\n",
    "\n",
    "\n",
    "namesnotdif = [\"CONTROL\", \"REGION\", \"STABBR\", \"UNITID\"]\n",
    "namesdif = list(set(col_common) - set(namesnotdif))\n",
    "\n",
    "print(len(namesnotdif))\n",
    "print(len(namesdif))\n",
    "\n",
    "\n",
    "print(\"Mean instead of nan\")\n",
    "\n",
    "for j in namesdif:\n",
    "\tsumma = 0\n",
    "\ttotal = 0\n",
    "\tnotnan = 0\n",
    "\tfor k in dfcommonuniv2014.index:\n",
    "\t\tif dfcommonuniv2014.loc[k,j] == dfcommonuniv2014.loc[k,j]:\n",
    "\t\t\tsumma = summa + float(dfcommonuniv2014.loc[k,j])\n",
    "\t\t\tnotnan = notnan + 1\n",
    "\t\ttotal = total + 1\n",
    "\tmean = summa / notnan\t\n",
    "\tfor i in dfcommonuniv2014.index:\n",
    "\t\tif dfcommonuniv2014.loc[i,j] != dfcommonuniv2014.loc[i,j]:\n",
    "\t\t\tdfcommonuniv2014.loc[i,j] = mean\n",
    "\n",
    "dfcommonuniv2014.to_csv('dfcommonuniv2014.csv', encoding='utf-8', columns=col_common)\n",
    "\n",
    "import scipy\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import os\n",
    "import os.path\n",
    "import csv\n",
    "\n",
    "#download files from DifferencesPart1\n",
    "df2010filled = pd.read_csv('dfcommonuniv2010_filled.csv', low_memory=False)\n",
    "df2014filled = pd.read_csv('dfcommonuniv2014_filled.csv', low_memory=False)\n",
    "print(df2010filled.shape)\n",
    "print(df2014filled.shape)\n",
    "\n",
    "\n",
    "df2010filled = df2010filled.drop(columns = \"Unnamed: 0\")\n",
    "df2014filled = df2014filled.drop(columns = \"Unnamed: 0\")\n",
    "\n",
    "\n",
    "#Setup columns which should and should not be used for calculating the changes\n",
    "col_names = df2010filled.columns\n",
    "print(len(col_names))\n",
    "namesnotdif = [\"CONTROL\", \"REGION\", \"STABBR\", \"UNITID\"]\n",
    "namesdif = list(set(col_names) - set(namesnotdif))\n",
    "print(namesdif)\n",
    "print(len(namesnotdif))\n",
    "print(len(namesdif))\n",
    "\n",
    "\n",
    "\n",
    "#Creating the differences dataframe\n",
    "dfdif = pd.DataFrame(index=df2010filled.index, columns=df2010filled.columns)\n",
    "\n",
    "#Calculating the differences\n",
    "for j in namesdif:\n",
    "\tfor i in df2010filled.index:\n",
    "\t\tdfdif.set_value(i,j, df2014filled.loc[i,j] - df2010filled.loc[i,j])\n",
    "for j in namesnotdif:\n",
    "\tfor i in df2010filled.index:\n",
    "\t\tdfdif.set_value(i,j, df2010filled.loc[i,j])\n",
    "\n",
    "#Creating the percentage differences dataframe\n",
    "dfpercentage = pd.DataFrame(index=df2010filled.index, columns=df2010filled.columns)\n",
    "\n",
    "#Calculating the percentage differences\n",
    "for j in namesdif:\n",
    "\tfor i in df2010filled.index:\n",
    "\t\tif df2014filled.loc[i,j] == df2010filled.loc[i,j]:\n",
    "\t\t\tdfpercentage.set_value(i,j,0)\n",
    "\t\telse:\n",
    "\t\t\tdfpercentage.set_value(i,j, ( (df2014filled.loc[i,j] - df2010filled.loc[i,j])/( 0.5*(df2014filled.loc[i,j] + df2010filled.loc[i,j]) ) )      )\n",
    "for j in namesnotdif:\n",
    "\tfor i in df2010filled.index:\n",
    "\t\tdfpercentage.set_value(i,j, df2010filled.loc[i,j])\n",
    "\n",
    "\n",
    "#Writhing difference and percentage differences files\n",
    "dfdifdrop = dfdif.drop([\"CONTROL\", \"REGION\", \"STABBR\", \"UNITID\"], axis = 1)\n",
    "print(dfdifdrop.shape)\n",
    "col_names_drop = dfdifdrop.columns\n",
    "print(col_names_drop)\n",
    "\n",
    "\n",
    "dfdif.to_csv('dfdif.csv', encoding='utf-8', columns=col_names)\n",
    "dfdifdrop.to_csv('dfdifdrop.csv', encoding='utf-8', columns=col_names_drop)\n",
    "dfpercentage.to_csv('dfpercentage.csv', encoding='utf-8', columns=col_names_drop)\n",
    "\n",
    "print(\"The differences file has the shape \",dfdif.shape)\n",
    "print(\"The percentage differences file has the shape\",dfpercentage.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created a new bin variable in stata in which its 1 if retention is greater than 2 SD and 0 otherwise\n",
    "\n",
    "df=pd.read_csv('MyEducationTest.csv',error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.tools as tls\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "\n",
    "plt.hist(df.ret_ft4_d)\n",
    "plt.hist(df.zret_ft4_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assings retention rate into 3 bins\n",
    "#df['rank'] = df['ret_ft4_d'].rank(method='first')\n",
    "\n",
    "#df['Bin'] = pd.qcut(df['rank'].values, 3).codes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print (df['Bin'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df.drop('zret_ft4_d', axis=1)\n",
    "df=df.drop('ret_ft4_d', axis=1)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.get_loc(\"ugds_unkn_d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving arrays to run models\n",
    "array = df.values\n",
    "\n",
    "X_features=array[:,1:63]\n",
    "Y_targetClass=df['bin']\n",
    "\n",
    "print(X_features)\n",
    "print(Y_targetClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_trainval, X_test, Y_trainval, Y_test= train_test_split(X_features, Y_targetClass, random_state= 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying standard scaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "scaler=preprocessing.StandardScaler().fit(X_trainval)\n",
    "X_trainval_transformed=scaler.transform(X_trainval)\n",
    "X_test_transformed1=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "kfolds=5\n",
    "\n",
    "best_score=0\n",
    "for c in [0.01,0.1,1,10,100,1000]:\n",
    "    LogRegModel1=LogisticRegression(C=c)\n",
    "    scores=cross_val_score(LogRegModel1,X_trainval_transformed,Y_trainval,cv=kfolds)\n",
    "    score=np.mean(scores)\n",
    "    print(scores)\n",
    "    if score > best_score:\n",
    "        best_score=score\n",
    "        best_parameter=c\n",
    "\n",
    "SelectedLogRegModel=LogisticRegression(C=best_parameter).fit(X_trainval_transformed,Y_trainval)\n",
    "\n",
    "test_score=SelectedLogRegModel.score(X_test_transformed1,Y_test)\n",
    "\n",
    "print(\"Best Score on validation set is: \",best_score)\n",
    "print(\"Chosen best parameter for model(C) is : \",best_parameter)\n",
    "print(\"Final score on test data is :\", test_score)\n",
    "\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = SelectedLogRegModel.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#runnning logistic regression to export coefecients\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "logit_model=sm.Logit(Y_targetClass,X_features)\n",
    "result=logit_model.fit()\n",
    "print(result.summary2())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureList=list(df.columns.values)\n",
    "FeaturesDF = pd.DataFrame()\n",
    "\n",
    "FeaturesDF['Feature Name']=featureList[1:63]\n",
    "FeaturesDF.index = np.arange(1, len(FeaturesDF) + 1)\n",
    "display(FeaturesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LDAmodelFitted = LinearDiscriminantAnalysis().fit(X_trainval_transformed, Y_trainval)\n",
    "cross_val_score(LDAmodelFitted,X_trainval_transformed,Y_trainval,cv=5)\n",
    "LDAmodelFitted.score(X_test_transformed1,Y_test)\n",
    "\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = LDAmodelFitted.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "QDAmodelFitted = QuadraticDiscriminantAnalysis().fit(X_trainval_transformed, Y_trainval)\n",
    "QDAmodelFitted.fit(X_trainval_transformed, Y_trainval)\n",
    "QDAmodelFitted.score(X_test_transformed1, Y_test)\n",
    "\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = QDAmodelFitted.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "kfolds=5\n",
    "\n",
    "best_score=0\n",
    "for c in [0.01,0.1,1,10,100,1000]:\n",
    "    svm_model_linear = SVC(kernel = 'linear', C = c).fit(X_trainval_transformed, Y_trainval) \n",
    "    scores=cross_val_score(svm_model_linear,X_trainval_transformed,Y_trainval,cv=kfolds)\n",
    "    score=np.mean(scores)\n",
    "    print(scores)\n",
    "    if score > best_score:\n",
    "        best_score=score\n",
    "        best_parameter=c\n",
    "    \n",
    "SelectedsvmModell=SVC(kernel = 'linear', C = best_parameter).fit(X_trainval_transformed,Y_trainval)\n",
    "\n",
    "test_score=SelectedsvmModell.score(X_test_transformed1,Y_test)\n",
    "\n",
    "print(\"Best Score on validation set is: \",best_score)\n",
    "print(\"Chosen best parameter for model(C) is : \",best_parameter)\n",
    "print(\"Final score on test data is :\", test_score)\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = SelectedsvmModell.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_trainval_transformed, Y_trainval) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = knn.score(X_test_transformed1, Y_test) \n",
    "print(accuracy) \n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = knn.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "gnb = GaussianNB().fit(X_trainval_transformed, Y_trainval) \n",
    "gnb_predictions = gnb.predict(X_test_transformed1) \n",
    "  \n",
    "# accuracy on X_test \n",
    "accuracy = gnb.score(X_test_transformed1, Y_test) \n",
    "print(accuracy) \n",
    "\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = gnb.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now doing decision tree\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "#training decision tree\n",
    "treeModel=DecisionTreeClassifier(max_depth=10, criterion= \"gini\")\n",
    "treeModel = treeModel.fit(X_trainval_transformed, Y_trainval)\n",
    "treeModel.score(X_test_transformed1, Y_test)\n",
    "\n",
    "#getting accuracy score\n",
    "y_pred = treeModel.predict(X_test_transformed1)\n",
    "y_pred\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = treeModel.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))\n",
    "\n",
    "\n",
    "treeModel.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now doing random forest\n",
    "\n",
    "#fitting random forest model\n",
    "forestModel= RandomForestClassifier (n_estimators=6, max_features=5, max_depth=10, random_state=0)\n",
    "forestModel = forestModel.fit(X_trainval_transformed, Y_trainval)\n",
    "forestModel.score(X_test_transformed1, Y_test)\n",
    "\n",
    "\n",
    "#getting accuracy score\n",
    "y_pred = forestModel.predict(X_test_transformed1)\n",
    "y_pred\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = forestModel.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now trying bosstin\n",
    "\n",
    "BoostModel= AdaBoostClassifier(n_estimators=10)\n",
    "BoostModel = BoostModel.fit(X_trainval_transformed, Y_trainval)\n",
    "BoostModel.score(X_test_transformed1, Y_test)\n",
    "\n",
    "\n",
    "#getting accuracy score\n",
    "y_pred = BoostModel.predict(X_test_transformed1)\n",
    "y_pred\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = BoostModel.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally trying neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "#fit a model\n",
    "MLPmodel = MLPClassifier(solver='sgd',activation='tanh',random_state = 0, hidden_layer_sizes=[10,5], alpha=0.5, max_iter=5000)\n",
    "MLPmodel.fit(X_trainval_transformed,Y_trainval)\n",
    "\n",
    "\n",
    "#getting accuracy score\n",
    "y_pred = MLPmodel.predict(X_test_transformed1)\n",
    "y_pred\n",
    "\n",
    "print (\"Accuracy is (Gradient Decent)\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = MLPmodel.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a model\n",
    "MLPmodel_L = MLPClassifier(solver='lbfgs',activation='tanh',random_state = 10, hidden_layer_sizes=[10,5], alpha=0.5, max_iter=5000)\n",
    "MLPmodel_L.fit(X_trainval_transformed,Y_trainval)\n",
    "\n",
    "\n",
    "#getting accuracy score\n",
    "y_pred = MLPmodel_L.predict(X_test_transformed1)\n",
    "y_pred\n",
    "\n",
    "print (\"Accuracy is (LBFGS)\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = MLPmodel_L.predict(X_test_transformed1)\n",
    "\n",
    "print (\"Accuracy is\", accuracy_score(Y_test,y_pred))\n",
    "\n",
    "cnf_matrix = confusion_matrix(Y_test, y_pred)\n",
    "print(\"Confusion Matrix\",cnf_matrix)\n",
    "\n",
    "average_precision = average_precision_score(Y_test, y_pred)\n",
    "\n",
    "print('Average precision: {0:0.2f}'.format(\n",
    "      average_precision))\n",
    "\n",
    "print('Recall Score:',recall_score(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now moving to sub sample to only high retention schools\n",
    "df2 = df.loc[df['bin'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving arrays to run models\n",
    "array = df2.values\n",
    "\n",
    "X_features=array[:,1:62]\n",
    "\n",
    "\n",
    "print(X_features)\n",
    "\n",
    "len(X_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now doing the hierarchical clustering\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X_features, 'ward')\n",
    "\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    linked,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iat[40,0]\n",
    "#university of phoenix-kentucky\n",
    "#university of phoenix-ohio\n",
    "#American InterContinental University-Houston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now doing the hier clustering\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X_features, 'average')\n",
    "\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    linked,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#now doing the hier clustering\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X_features, 'single')\n",
    "\n",
    "\n",
    "# calculate full dendrogram\n",
    "plt.figure(figsize=(25, 10))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('sample index')\n",
    "plt.ylabel('distance')\n",
    "dendrogram(\n",
    "    linked,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
